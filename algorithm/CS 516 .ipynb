{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "Because of the sparsity of the dataset we need the update our user based collobrative filtering approach to meet the needs of sparse data. This can be acvieved by incorporating a matrix factorization algorithm. Compared regular approaches like collobrative or content filtering *footnote, matrix factorization allows us the uncover the latent features underlying two different factors.This is also the method used by companies such as Netflix (citation).\n",
    "\n",
    "### Explanation of Matrix Factorization\n",
    "\n",
    "We want to estimate a matrix $Q_{kxk}$ that captures k latent features for the users and beers. Specifically we want to estimate the vectors $b_i$, $u_j$ of length k for each users and beer in our data sets. The vector $b_i$ for the the beer will represent to which extent the beer i posseses the factor that are being interested by the users, whereas similarly $u_i$ will represent the which extent user j is interested in these factors.\n",
    "\n",
    "When we take the dot product of these 2 vectors, we can estimate the ratings for a specific userson the specific type of beer. \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{r_{iu}} & = \\ b^T_{i} p_{j}\n",
    "\\end{align}\n",
    "\n",
    "Assuming our initial rating matrix R has dimensions of $mxn$, we cab combine these vectors into two matrices and illustrate the matrix factorization. \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{R} & = \\ UxB^T\n",
    "\\end{align}\n",
    "\n",
    "Where U is a $mxk$ matrix that represent each users assosication with latent factors and B is a $nxk$ matrix that represents each beers association with the latent factors. We will use Stochastic Gradient Descent to estimate the matrices Q and P. Our loss/objective function can be defined as :\n",
    "\\begin{align}\n",
    "\\hat{R} & = \\ UxB^T\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "*Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yamac\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import sparse\n",
    "import numba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yamac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"final_data.csv\")\n",
    "dfc=df[[\"score_overall\",\"user_id\",\"beer_names\",\"beer_id\",\"brewery_name\"]]\n",
    "\n",
    "##df=pd.read_csv(\"beer_reviews.csv\")\n",
    "##dfc=df[[\"review_overall\",\"review_profilename\",\"beer_name\",\"beer_beerid\",\"brewery_name\"]]\n",
    "\n",
    "beers=dfc.groupby('beer_id').count().query(\"score_overall >=10\").index\n",
    "users=dfc.groupby('user_id').count().query(\"score_overall >=10\").index\n",
    "df_filtered=dfc[dfc.beer_id.isin(beers)][dfc.user_id.isin(users)]\n",
    "\n",
    "users=pd.factorize(df_filtered.user_id)[0]\n",
    "beers=pd.factorize(df_filtered.beer_id)[0]\n",
    "index_to_userid=dict(zip(users,df_filtered.user_id))\n",
    "index_into_beerid=dict(zip(beers,df_filtered.beer_id))\n",
    "\n",
    "index_into_beerid = {v: k for k, v in index_into_beerid.items()}\n",
    "index_to_userid = {v: k for k, v in index_to_userid.items()}\n",
    "R=np.zeros((len(index_into_beerid),len(index_to_userid))).T\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    R[index_to_userid[row['user_id']],index_into_beerid[row['beer_id']]]=row['score_overall']\n",
    "    \n",
    "index_into_beerid = {v: k for k, v in index_into_beerid.items()}\n",
    "index_to_userid = {v: k for k, v in index_to_userid.items()}\n",
    "\n",
    "index_into_beername=dict(zip(beers, df_filtered.beer_names+ \" by \"+ df_filtered.brewery_name ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Without TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factor(X,epochs=25000,k=4,lr=0.007,beta=0.001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    r_hat=Q@P\n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%1000==0:\n",
    "            loss=np.sum((np.square(X[z_i,z_j]-r_hat[z_i,z_j])))\n",
    "            print(\"Epoch : \" + str(epoch)+ \", Loss: \"+str(loss))\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]\n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "        r_hat=Q@P\n",
    "    return Q@P\n",
    "     \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(\"double[:,:](double[:,:],i8,i8,double,double)\",nopython=True)\n",
    "def matrix_factor_numba(X,epochs=25000,k=4,lr=0.0005,beta=0.0001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%100==0:\n",
    "            print(epoch)\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]    \n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "    r_hat=Q@P\n",
    "    return r_hat\n",
    "     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_factor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matrix_factor' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r_hat1=matrix_factor(X,epochs=10000,k=3,lr=0.005,beta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "Wall time: 1h 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r_hat2=matrix_factor_numba(R,epochs=2500,k=3,lr=0.005,beta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-61e04846d20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr_hat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_hat2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r_hat=(np.round(r_hat2)*4)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"r_hat\",r_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-44660c99391d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr_hat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_hat2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mround_\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   2849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2850\u001b[0m     \"\"\"\n\u001b[1;32m-> 2851\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36maround\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \"\"\"\n\u001b[1;32m-> 2837\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'round'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r_hat=np.round(r_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13562, 19714)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"R_hat\",r_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"r_hat\",R_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application With Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1,0,0,0,5],[0,0,4,1,0],[0,2,1,0,0],[0,0,4,4,1],[2,3,1,0,0],[5,3,1,0,0]],dtype=\"float64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13562, 19714)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yamac\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 267361268 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "    m,n=R_f.shape\n",
    "    \n",
    "    Rating= tf.placeholder(tf.float32, [m,n])\n",
    "    Q = tf.Variable(tf.truncated_normal([int(m), k], stddev=0.2, mean=0), name=\"users\")\n",
    "    P=tf.Variable(tf.truncated_normal([k, int(n)], stddev=0.2, mean=0), name=\"beers\")\n",
    "        \n",
    "    \n",
    "    r_hat=tf.matmul(Q,P)\n",
    "    mask =  tf.greater(Rating, 0)\n",
    "    R_h_values = tf.boolean_mask(r_hat, mask)\n",
    "    R_values = tf.boolean_mask(Rating, mask)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(R_h_values, R_values))+0.0002*(tf.norm(Q)+tf.norm(P))\n",
    "    \n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix_Factorization(X,k=3,lr=0.001,beta=0.0005,epochs=25000,tolerance=0.001):\n",
    "    m,n=X.shape\n",
    "    \n",
    "    Rating= tf.placeholder(tf.float32, [m,n])\n",
    "    Q = tf.Variable(tf.truncated_normal([int(m), k], stddev=0.2, mean=0), name=\"users\")\n",
    "    P=tf.Variable(tf.truncated_normal([k, int(n)], stddev=0.2, mean=0), name=\"beers\") \n",
    "    \n",
    "    r_hat=tf.matmul(Q,P)\n",
    "    mask =  tf.greater(Rating, 0)\n",
    "    R_h_values = tf.boolean_mask(r_hat, mask)\n",
    "    R_values = tf.boolean_mask(Rating, mask)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(R_values,R_h_values))+beta*(tf.norm(Q)+tf.norm(P))\n",
    "    \n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(\"STARTING THE DESCENT\")\n",
    "\n",
    "    for i in range(epochs):\n",
    "        if i % 10 == 0:\n",
    "            l=sess.run(tf.reduce_mean(tf.squared_difference(R_h_values, R_values)),feed_dict={Rating:X})\n",
    "            print(\"EPOCH \" +str(i)+ \", Loss: \" + str(l))\n",
    "            if l<tolerance:\n",
    "                break\n",
    "        sess.run(train_step,feed_dict={Rating:X})\n",
    "    \n",
    "    final=tf.matmul(Q,P)\n",
    "    final_res = sess.run([final])[0]\n",
    "    sess.close()\n",
    "    return np.round(final_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yamac\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yamac\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 953518245 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING THE DESCENT\n",
      "EPOCH 0, Loss: 15.934969\n",
      "EPOCH 10, Loss: 15.934969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-5355fc802d5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mzz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMatrix_Factorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-c789c2189cec>\u001b[0m in \u001b[0;36mMatrix_Factorization\u001b[1;34m(X, k, lr, beta, epochs, tolerance)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mRating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zz=Matrix_Factorization(R,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.dynamic_partition(tf.reshape(r_hat, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=Matrix_Factorization(R_f,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ind=list(user_ind)\n",
    "item_ind=list(item_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=np.zeros((30000,60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=R_f.shape\n",
    "    \n",
    "Rating= tf.placeholder(tf.float32, [m,n])\n",
    "Q = tf.Variable(tf.truncated_normal([int(m), 3], stddev=0.2, mean=1), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, int(n)], stddev=0.2, mean=1), name=\"beers\")\n",
    "\n",
    "\n",
    "r_hat=tf.matmul(Q,P)\n",
    "mask =  tf.greater(Rating, 0)\n",
    "R_h_values = tf.boolean_mask(r_hat, mask)\n",
    "R_values = tf.boolean_mask(Rating, mask)\n",
    "    \n",
    "loss = tf.reduce_mean(tf.squared_difference(R_h_values, R_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.greater(X, 0)\n",
    "non_zero_array = tf.boolean_mask(X, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_Factorization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train_step = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ind=user_ind.reshape(1571801,1)\n",
    "item_ind=item_ind.reshape(1571801,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gather(Rating,[user_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_Factorization(R,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(10000):\n",
    "    if i % 500 == 0:\n",
    "        print(\"EPOCH \" +str(i))\n",
    "    sess.run(train_step,feed_dict={R:X})\n",
    "    \n",
    "final=tf.matmul(Q,P)\n",
    "final_res = sess.run([final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= tf.placeholder(tf.float32, [5,5])\n",
    "Q = tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, 5], stddev=0.2, mean=0), name=\"beers\")i\n",
    "\n",
    "r_hat=tf.matmul(Q,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_h_values = tf.gather(tf.reshape(r_hat, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, name=\"existing_ratings2\")\n",
    "R_values=tf.gather(tf.reshape(R, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, name=\"existing_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(R_h_values, R_values))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.002)\n",
    "train_step = optimizer.minimize(loss, global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    if i % 500 == 0:\n",
    "        print(\"EPOCH \" +str(i))\n",
    "    sess.run(train_step,feed_dict={R:X})\n",
    "    \n",
    "final=tf.matmul(Q,P)\n",
    "final_res = sess.run([final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=np.vstack((X,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m=R.shape\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for k in range(len(i)):\n",
    "    sess.run(grad_descent)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(Q[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eis=R[0,0]-tf.tensordot(Q[0],P[:,0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "out=sess.run(rows,feed_dict={r:X})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=np.where(X!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(X!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_q(k):\n",
    "    ps=[]\n",
    "    qs=[]\n",
    "    for i in range(k):\n",
    "        ps.append(tf.Variable(tf.zeros([k])))\n",
    "        qs.append(tf.Variable(tf.zeros([k])))\n",
    "    return qs,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sA = sparse.csr_matrix(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sA[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in R:\n",
    "    if np.sum(i>0)<=3:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.where(R>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=z[0]\n",
    "j=z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=np.random.rand(6,3)\n",
    "P=np.random.rand(6,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1571801):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=sparse.rand(3, 4, density=0.25, format=\"csr\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factor(X,epochs=15000,k=4,lr=0.007,beta=0.001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch : \" + str(epoch))\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]\n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "    return Q@P\n",
    "     \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= tf.placeholder(tf.float32, [5,5])\n",
    "Q = tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, 5], stddev=0.2, mean=0), name=\"beers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P[1]-0.002*Q[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[:,0]+2.0*0.0002*(X[0,1]-tf.tensordot(Q[:,1],P[0],axes=1))*P[1]-0.002*Q[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1\n",
    "lr=0.002\n",
    "beta=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[:,i]=Q[:,i]+2.0*lr*(X[i,j]-tf.tensordot(Q[:,1],P[0],axes=1))*P[j]-beta*Q[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[i]=Q[i]+2*lr*(X[i,j]-tf.tensordot(Q[:,1],P[0],axes=1))*P[j]-beta*Q[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(X,Q,P,i,j):\n",
    "    lr=0.002\n",
    "    beta=0.001\n",
    "    Q[i]=Q[i]+2*lr*(X[i,j]-tf.matmul(Q[i],P[:,j]))*P[:,j]-beta*Q[i]\n",
    "    P[:,j]=P[:,j]+2*lr*(X[i,j]-tf.matmul(Q[i],P[:,j]))*Q[i]-beta*P[:,j]\n",
    "    Q@P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=np.random.rand(6,3)\n",
    "P=np.random.rand(6,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_descent(X,Q,P,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"den.np\",R_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
