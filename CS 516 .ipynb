{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "Because of the sparsity of the dataset we need the update our user based collobrative filtering approach to meet the needs of sparse data. This can be acvieved by incorporating a matrix factorization algorithm. Compared regular approaches like collobrative or content filtering *footnote, matrix factorization allows us the uncover the latent features underlying two different factors.This is also the method used by companies such as Netflix (citation).\n",
    "\n",
    "### Explanation of Matrix Factorization\n",
    "\n",
    "We want to estimate a matrix $Q_{kxk}$ that captures k latent features for the users and beers. Specifically we want to estimate the vectors $b_i$, $u_j$ of length k for each users and beer in our data sets. The vector $b_i$ for the the beer will represent to which extent the beer i posseses the factor that are being interested by the users, whereas similarly $u_i$ will represent the which extent user j is interested in these factors.\n",
    "\n",
    "When we take the dot product of these 2 vectors, we can estimate the ratings for a specific userson the specific type of beer. \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{r_{iu}} & = \\ b^T_{i} p_{j}\n",
    "\\end{align}\n",
    "\n",
    "Assuming our initial rating matrix R has dimensions of $mxn$, we cab combine these vectors into two matrices and illustrate the matrix factorization. \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{R} & = \\ UxB^T\n",
    "\\end{align}\n",
    "\n",
    "Where U is a $mxk$ matrix that represent each users assosication with latent factors and B is a $nxk$ matrix that represents each beers association with the latent factors. We will use Stochastic Gradient Descent to estimate the matrices Q and P. Our loss/objective function can be defined as :\n",
    "\\begin{align}\n",
    "\\hat{R} & = \\ UxB^T\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "*Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import sparse\n",
    "import numba\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"final_data.csv\")\n",
    "dfc=df[[\"score_overall\",\"user_id\",\"beer_names\",\"beer_id\",\"brewery_name\"]]\n",
    "\n",
    "##df=pd.read_csv(\"beer_reviews.csv\")\n",
    "##dfc=df[[\"review_overall\",\"review_profilename\",\"beer_name\",\"beer_beerid\",\"brewery_name\"]]\n",
    "\n",
    "beers=dfc.groupby('beer_id').count().query(\"score_overall >=10\").index\n",
    "users=dfc.groupby('user_id').count().query(\"score_overall >=10\").index\n",
    "df_filtered=dfc[dfc.beer_id.isin(beers)][dfc.user_id.isin(users)]\n",
    "\n",
    "users=pd.factorize(df_filtered.user_id)[0]\n",
    "beers=pd.factorize(df_filtered.beer_id)[0]\n",
    "index_to_userid=dict(zip(users,df_filtered.user_id))\n",
    "index_into_beerid=dict(zip(beers,df_filtered.beer_id))\n",
    "\n",
    "index_into_beerid = {v: k for k, v in index_into_beerid.items()}\n",
    "index_to_userid = {v: k for k, v in index_to_userid.items()}\n",
    "R=np.zeros((len(index_into_beerid),len(index_to_userid))).T\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    R[index_to_userid[row['user_id']],index_into_beerid[row['beer_id']]]=row['score_overall']\n",
    "    \n",
    "index_into_beerid = {v: k for k, v in index_into_beerid.items()}\n",
    "index_to_userid = {v: k for k, v in index_to_userid.items()}\n",
    "\n",
    "index_into_beername=dict(zip(beers, df_filtered.beer_names+ \" by \"+ df_filtered.brewery_name ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_into_beername = {v: k for k, v in index_into_beername.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"beers.pickle\",\"wb\")\n",
    "pickle.dump(index_into_beername, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Without TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factor(X,epochs=25000,k=4,lr=0.007,beta=0.001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    r_hat=Q@P\n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%1000==0:\n",
    "            loss=np.sum((np.square(X[z_i,z_j]-r_hat[z_i,z_j])))\n",
    "            print(\"Epoch : \" + str(epoch)+ \", Loss: \"+str(loss))\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]\n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "        r_hat=Q@P\n",
    "    return Q@P,Q,P\n",
    "     \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_user(Q,P,user,lr=0.007,beta=0.001,epochs=10000):\n",
    "    user_hat=np.zeros(len(user))\n",
    "    n,m=Q.shape\n",
    "    Q_n=np.random.rand(m)\n",
    "    z_i=np.where(user>0)\n",
    "    for epoch in range(epochs):\n",
    "        for u in range(len(z_i)):\n",
    "            i=z_i[0][u]\n",
    "            Q_n=Q_n+(2*lr*(user[i]-np.dot(Q_n,P[:,i]))*P[:,i]).T-beta*Q_n\n",
    "    for i in range(len(P.T)):\n",
    "        user_hat[i]=np.dot(Q_n,P.T[i])   \n",
    "    return user_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit(\"Tuple((double[:,:],double[:,:]))(double[:,:],i8,i8,double,double)\",nopython=True)\n",
    "def matrix_factor_numba(X,epochs=25000,k=4,lr=0.0005,beta=0.0001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%100==0:\n",
    "            print(epoch)\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]    \n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "    r_hat=Q@P\n",
    "    return r_hat,Q,P\n",
    "     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "Wall time: 23min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r_hat2,Q2,P2=matrix_factor_numba(R,epochs=1000,k=3,lr=0.005,beta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"r_hat\",r_hat2)\n",
    "np.save(\"Q\",Q2)\n",
    "np.save(\"P\",P2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.load(\"r_hat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beers = pickle.load( open( \"beers.pickle\", \"rb\" ) )\n",
    "beers = {v: k for k, v in beers.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=np.array([1,2,5,3,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-z).argsort()[:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application With Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array([[1,0,0,0,5],[0,0,4,1,0],[0,2,1,0,0],[0,0,4,4,1],[2,3,1,0,0],[5,3,1,0,0]],dtype=\"float64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Matrix_Factorization(X,k=3,lr=0.001,beta=0.0005,epochs=25000,tolerance=0.001):\n",
    "    m,n=X.shape\n",
    "    \n",
    "    Rating= tf.placeholder(tf.float32, [m,n])\n",
    "    Q = tf.Variable(tf.truncated_normal([int(m), k], stddev=0.2, mean=0), name=\"users\")\n",
    "    P=tf.Variable(tf.truncated_normal([k, int(n)], stddev=0.2, mean=0), name=\"beers\") \n",
    "    \n",
    "    r_hat=tf.matmul(Q,P)\n",
    "    mask =  tf.greater(Rating, 0)\n",
    "    R_h_values = tf.boolean_mask(r_hat, mask)\n",
    "    R_values = tf.boolean_mask(Rating, mask)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(R_values,R_h_values))+beta*(tf.norm(Q)+tf.norm(P))\n",
    "    \n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(\"STARTING THE DESCENT\")\n",
    "\n",
    "    for i in range(epochs):\n",
    "        if i % 1000 == 0:\n",
    "            l=sess.run(tf.reduce_mean(tf.squared_difference(R_h_values, R_values)),feed_dict={Rating:X})\n",
    "            print(\"EPOCH \" +str(i)+ \", Loss: \" + str(l))\n",
    "            if l<tolerance:\n",
    "                break\n",
    "        sess.run(train_step,feed_dict={Rating:X})\n",
    "    \n",
    "    final=tf.matmul(Q,P)\n",
    "    final_res = sess.run([final])[0]\n",
    "    return np.round(final_res),sess.run(Q),sess.run(P)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING THE DESCENT\n",
      "EPOCH 0, Loss: 8.766003\n",
      "EPOCH 1000, Loss: 8.172392\n",
      "EPOCH 2000, Loss: 6.2677407\n",
      "EPOCH 3000, Loss: 2.661744\n",
      "EPOCH 4000, Loss: 1.0015736\n",
      "EPOCH 5000, Loss: 0.47182128\n",
      "EPOCH 6000, Loss: 0.28467563\n",
      "EPOCH 7000, Loss: 0.21309137\n",
      "EPOCH 8000, Loss: 0.1701608\n",
      "EPOCH 9000, Loss: 0.13640362\n",
      "EPOCH 10000, Loss: 0.10966242\n",
      "EPOCH 11000, Loss: 0.08998828\n",
      "EPOCH 12000, Loss: 0.07642423\n",
      "EPOCH 13000, Loss: 0.06722689\n",
      "EPOCH 14000, Loss: 0.060698647\n",
      "EPOCH 15000, Loss: 0.055616673\n",
      "EPOCH 16000, Loss: 0.051247403\n",
      "EPOCH 17000, Loss: 0.047201093\n",
      "EPOCH 18000, Loss: 0.043290023\n",
      "EPOCH 19000, Loss: 0.039436676\n",
      "EPOCH 20000, Loss: 0.035622418\n",
      "EPOCH 21000, Loss: 0.031859685\n",
      "EPOCH 22000, Loss: 0.02818217\n",
      "EPOCH 23000, Loss: 0.02463113\n",
      "EPOCH 24000, Loss: 0.021254275\n"
     ]
    }
   ],
   "source": [
    "zz,Q,P=Matrix_Factorization(X,epochs=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new=np.array([0,0,5,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_another(X,Q,P,new):\n",
    "    m,n=X.shape\n",
    "    Rating= tf.placeholder(tf.float32, [m,n])\n",
    "    Q= tf.placeholder(tf.float32, [m,k])\n",
    "    P= tf.placeholder(tf.float32, [m,k])\n",
    "    Q = tf.Variable(tf.truncated_normal([int(m), k], stddev=0.2, mean=0), name=\"users\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8729577 , -1.0004058 , -0.25965554],\n",
       "       [ 1.571367  ,  1.1707896 , -0.46825612],\n",
       "       [-0.0993017 , -0.04132294, -1.058435  ],\n",
       "       [ 0.40730035,  1.147678  , -2.0240343 ],\n",
       "       [-0.02403948, -0.15282382, -1.3832246 ],\n",
       "       [ 0.321137  , -1.5032159 , -1.8284739 ]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.dynamic_partition(tf.reshape(r_hat, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz=Matrix_Factorization(R_f,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ind=list(user_ind)\n",
    "item_ind=list(item_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(item_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z=np.zeros((30000,60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m,n=R_f.shape\n",
    "    \n",
    "Rating= tf.placeholder(tf.float32, [m,n])\n",
    "Q = tf.Variable(tf.truncated_normal([int(m), 3], stddev=0.2, mean=1), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, int(n)], stddev=0.2, mean=1), name=\"beers\")\n",
    "\n",
    "\n",
    "r_hat=tf.matmul(Q,P)\n",
    "mask =  tf.greater(Rating, 0)\n",
    "R_h_values = tf.boolean_mask(r_hat, mask)\n",
    "R_values = tf.boolean_mask(Rating, mask)\n",
    "    \n",
    "loss = tf.reduce_mean(tf.squared_difference(R_h_values, R_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.greater(X, 0)\n",
    "non_zero_array = tf.boolean_mask(X, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix_Factorization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train_step = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ind=user_ind.reshape(1571801,1)\n",
    "item_ind=item_ind.reshape(1571801,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rating.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(user_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.gather(Rating,[user_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix_Factorization(R,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(10000):\n",
    "    if i % 500 == 0:\n",
    "        print(\"EPOCH \" +str(i))\n",
    "    sess.run(train_step,feed_dict={R:X})\n",
    "    \n",
    "final=tf.matmul(Q,P)\n",
    "final_res = sess.run([final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R= tf.placeholder(tf.float32, [5,5])\n",
    "Q = tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, 5], stddev=0.2, mean=0), name=\"beers\")i\n",
    "\n",
    "r_hat=tf.matmul(Q,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_h_values = tf.gather(tf.reshape(r_hat, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, name=\"existing_ratings2\")\n",
    "R_values=tf.gather(tf.reshape(R, [-1]), user_ind * tf.shape(r_hat)[1] + item_ind, name=\"existing_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(R_h_values, R_values))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.002)\n",
    "train_step = optimizer.minimize(loss, global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    if i % 500 == 0:\n",
    "        print(\"EPOCH \" +str(i))\n",
    "    sess.run(train_step,feed_dict={R:X})\n",
    "    \n",
    "final=tf.matmul(Q,P)\n",
    "final_res = sess.run([final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z=np.vstack((X,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n,m=R.shape\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for k in range(len(i)):\n",
    "    sess.run(grad_descent)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int(Q[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eis=R[0,0]-tf.tensordot(Q[0],P[:,0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "out=sess.run(rows,feed_dict={r:X})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy=np.where(X!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(X!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_q(k):\n",
    "    ps=[]\n",
    "    qs=[]\n",
    "    for i in range(k):\n",
    "        ps.append(tf.Variable(tf.zeros([k])))\n",
    "        qs.append(tf.Variable(tf.zeros([k])))\n",
    "    return qs,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sA = sparse.csr_matrix(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sA[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in R:\n",
    "    if np.sum(i>0)<=3:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=np.where(R>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=z[0]\n",
    "j=z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q=np.random.rand(6,3)\n",
    "P=np.random.rand(6,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (1571801):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z=sparse.rand(3, 4, density=0.25, format=\"csr\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factor(X,epochs=15000,k=4,lr=0.007,beta=0.001):\n",
    "    n,m=X.shape\n",
    "    Q=np.random.rand(n,k)\n",
    "    P=np.random.rand(m,k).T  \n",
    "    z_i,z_j=np.where(X>0)\n",
    "    z_i=list(z_i)\n",
    "    z_j=list(z_j)\n",
    "    n=len(z_i)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch : \" + str(epoch))\n",
    "        for u in range(n):\n",
    "            i=z_i[u]\n",
    "            j=z_j[u]\n",
    "            Q[i]=Q[i]+2*lr*(X[i,j]-Q[i]@P[:,j])*P[:,j]-beta*Q[i]\n",
    "            P[:,j]=P[:,j]+2*lr*(X[i,j]-Q[i]@P[:,j])*Q[i]-beta*P[:,j]\n",
    "    return Q@P\n",
    "     \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R= tf.placeholder(tf.float32, [5,5])\n",
    "Q = tf.Variable(tf.truncated_normal([5, 3], stddev=0.2, mean=0), name=\"users\")\n",
    "P=tf.Variable(tf.truncated_normal([3, 5], stddev=0.2, mean=0), name=\"beers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P[1]-0.002*Q[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q[:,0]+2.0*0.0002*(X[0,1]-tf.tensordot(Q[:,1],P[0],axes=1))*P[1]-0.002*Q[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1\n",
    "lr=0.002\n",
    "beta=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q[:,i]=Q[:,i]+2.0*lr*(X[i,j]-tf.tensordot(Q[:,1],P[0],axes=1))*P[j]-beta*Q[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q[i]=Q[i]+2*lr*(X[i,j]-tf.tensordot(Q[:,1],P[0],axes=1))*P[j]-beta*Q[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_descent(X,Q,P,i,j):\n",
    "    lr=0.002\n",
    "    beta=0.001\n",
    "    Q[i]=Q[i]+2*lr*(X[i,j]-tf.matmul(Q[i],P[:,j]))*P[:,j]-beta*Q[i]\n",
    "    P[:,j]=P[:,j]+2*lr*(X[i,j]-tf.matmul(Q[i],P[:,j]))*Q[i]-beta*P[:,j]\n",
    "    Q@P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q=np.random.rand(6,3)\n",
    "P=np.random.rand(6,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_descent(X,Q,P,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"den.np\",R_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
